{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2a7d8ec",
   "metadata": {},
   "source": [
    "# PYNQ 201 - MNIST\n",
    "----\n",
    "This notebook will introduce you to the MNIST database and its accompanying MNIST Classifier model. The goal of this notebook is to: \n",
    "* understand what the MNIST database is,\n",
    "* learn how to use the MNIST Classifier Model, \n",
    "* program the grove <span style=\"color:red\">R</span><span style=\"color:green\">G</span><span style=\"color:blue\">B</span> LED stick, and\n",
    "* explore how we can use the MNIST database and model in different ways! \n",
    "\n",
    "### What is the MNIST Database‚ùì ###\n",
    "MNIST stands for the \"Modified National Institute of Standards and Technology\" database. It can be said that this database is the \"Hello World!\" implementation to machine learning, since it is a great starting point for people interested in learning about image classification and pattern recognition. \n",
    "\n",
    "The MNIST Database consists of 70,000 small, square 28x28 pixel grayscale images of handwritten single digits between 0 and 9. That's a lot! These images all have labels with the respective digits they represent. \n",
    "\n",
    "But why is this MNIST Database so important? While this famous dataset contains handwritten digits, it has begun to inspire similar datasets that contain images and data in different areas such as fashion, medical images, sign language, and skin cancers. These datasets are used to train models that can help to predict and detect outcomes from inputs. For example, there is another dataset called the Skin Cancer MNIST that has over 10,000 images of 7 different classes of skin cancer. This has enabled engineers and scientists to create machine learning models to classify skin cancer from images taken from their patients. \n",
    "\n",
    "This is only the beginning to what machine learning databases and models can accomplish! \n",
    "\n",
    "![MNISTdatabase.png](img\\MNISTdatabase.png)\n",
    "<center>Here are 128 out of the 70,000 images in the database!</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c80a89",
   "metadata": {},
   "source": [
    "\n",
    "### What is the MNIST Classifier Model used in this notebook‚ùì ###\n",
    "The model you will be exploring in this notebook is called the MNIST Classifier Model. This model is a type of Convolutional Neural Network (CNN) model which is good for identifying features and patterns in images. The MNIST Classifier Model has already been trained on the MNIST dataset for you. \n",
    "\n",
    "Note that during training, this CNN model has to learn to recognize different patterns in the images by adjusting the weights and biases of its neurons. It uses a labeled dataset, where each image in the dataset knows its correct digit, to iteratively improve its predictions. In simpler terms, this model uses the correct answers you give it to predict more accurate answers for images you give it in the future!\n",
    "\n",
    "\n",
    "![mnistpic2.PNG =200x200](img\\MNISTmodel.PNG)\n",
    "<center>This is a great visual example of what the MNIST Classifier Model is! There are different layers that</center>\n",
    "    <center>recognize different patterns of the image you input into it!</center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab9553d4",
   "metadata": {},
   "source": [
    "## üòé Let's get started! üòé ##\n",
    "----\n",
    "### üßê Setup üßê ###\n",
    "Connect these peripherals to your board!\n",
    "* USB Camera\n",
    "\n",
    "<img align =\"left\" src=\"img\\logi_webcam.jpg\"  width=\"150\" height=\"150\">\n",
    "\n",
    "<br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "\n",
    "* PMOD Adapter\n",
    "    * RGB LED Stick\n",
    "    \n",
    "    <img align =\"left\" src=\"img\\pynq_grove_adapter.jpg\"  width=\"150\" height=\"150\"> <img align =\"center\" src=\"img\\rgb_led_bar.png\"  width=\"150\" height=\"150\">\n",
    "<br/><br/>\n",
    "\n",
    "### Step 1: Load dpu.bit Overlay  ###\n",
    "The board in front of you has a Field Programmable Gate Array (FPGA) on it that needs to be programmed before the board can be used. We apply designs called overlays that we can design however we want. For this and future notebooks, you will program the FPGA on your board with a pre-built dpu overlay called üî•dpu.bitüî•."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7403b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this library is for downloading the overlay to the board\n",
    "from pynq_dpu import DpuOverlay\n",
    "# this line will be used later when we want to use the RGB LED Stick\n",
    "from pynq_peripherals import PmodGroveAdapter\n",
    "# downloading the overlay to the board\n",
    "overlay = DpuOverlay(\"dpu.bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db303b80",
   "metadata": {},
   "source": [
    "Next let's write some code to prepare the RGB LED stick!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19595973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the PMOD adapter\n",
    "adapter = PmodGroveAdapter(overlay.PMODA, G4='grove_led_stick')\n",
    "# the 'G4' means that we are attaching the RGB LED stick to the G4 \n",
    "# port on the PMOD Adapter\n",
    "\n",
    "# define the device object\n",
    "led_stick = adapter.G4\n",
    "# this is so we can use the name led_stick when \n",
    "# we want to reference the peripheral later\n",
    "\n",
    "# let's also clear the stick so we start from a fresh state\n",
    "led_stick.clear()\n",
    "# this is a good habit in case you\n",
    "# plan on changing the colors later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d5b71e",
   "metadata": {},
   "source": [
    "### Step 2: Load the MNIST Classifier Model  ###\n",
    "This line loads a model that has already been compiled for you! Remember this line in case you want to load future models onto your board! üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da54c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay.load_model(\"dpu_mnist_classifier.xmodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01502b31",
   "metadata": {},
   "source": [
    "### üìö Step 3: Import Libraries üìö ###\n",
    "Let's import some libraries we will need later in this notebook as well. A library is a collection of pre-written code that provides you with different types of functionality so you don't have to write it yourself from scratch! We can thank other developers who shared these libraries for their time and effort!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05535774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time                                      # various time-related functions\n",
    "import os                                                  # portable way of using operating system dependent functionality\n",
    "import numpy as np                                         # contains multidimensional array and matrix data structures\n",
    "import mnist                                               # functions to load dataset and labels \n",
    "import matplotlib.pyplot as plt                            # data visualization library for plots, graphs and charts\n",
    "%matplotlib inline\n",
    "from six.moves import urllib                               # imports a mixture of urllib, urllib2 and urlparse with Python2\n",
    "import cv2                                                 # computer vision library for solving computer vision problems\n",
    "\n",
    "# the mnist package requires some additional headers for URL requests\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a869c72",
   "metadata": {},
   "source": [
    "### Step 4: Load test data ### \n",
    "Let's load up some of the images from the MNIST dataset! Some models require specific types of images as input, and the MNIST classifier model is one of them! \n",
    "\n",
    "Did you notice how most of the images in the database have a black background with a white digit?\n",
    "This means that the images will require some pre-processing. For the NMIST database, there are two pre-processing steps we need to do to the test images before we can use it: \n",
    "1. Normalize the elements to floating-point or decimal numbers ranging from 0 to 1\n",
    "2. Convert each input to an array of 3 dimensions \n",
    "\n",
    "It's ok if there is something you don't understand! Please make sure to ask questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2f1061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the test_images method contains about 10,000 images from the MNIST database!\n",
    "raw_data = mnist.test_images()\n",
    "print (raw_data.shape)\n",
    "\n",
    "normalized_data = np.asarray(raw_data/255, dtype=np.float32)\n",
    "print (normalized_data.shape)\n",
    "\n",
    "test_data = np.expand_dims(normalized_data, axis=3)\n",
    "print (test_data.shape)\n",
    "\n",
    "test_label = mnist.test_labels()\n",
    "\n",
    "print(\"Total number of test images: {}\".format(test_data.shape[0]))\n",
    "print(\"  Dimension of each picture: {}x{}\".format(test_data.shape[1],\n",
    "                                                  test_data.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07323f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also display different digits in the database! \n",
    "# Try changing the \"505\" in the next two lines to a \n",
    "# different number from 0-9999  \n",
    "# make sure to rerun the cell when you change code!\n",
    "plt.imshow(test_data[505,:,:,0], 'gray')\n",
    "plt.title('Label: {}'.format(test_label[505]))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea5e11",
   "metadata": {},
   "source": [
    "### Step 5: More set up\n",
    "The next few cells of code will be seen in a bit throughout future notebooks and help models store and process data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb841c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a runner instance that has a number of member functions to control \n",
    "# the execution and get the input and output tensors\n",
    "dpu = overlay.runner\n",
    "\n",
    "# get the input and output tensors\n",
    "inputTensors = dpu.get_input_tensors()\n",
    "outputTensors = dpu.get_output_tensors()\n",
    "\n",
    "# define the required input and output shapes of the data being put into and received from the model\n",
    "shapeIn = tuple(inputTensors[0].dims)\n",
    "shapeOut = tuple(outputTensors[0].dims)\n",
    "outputSize = int(outputTensors[0].get_data_size() / shapeIn[0])\n",
    "\n",
    "# create a new array of given shape and type, without initializing entries\n",
    "softmax = np.empty(outputSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdf8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty array for output data with the correct shape (shapeOut) and type (float32)\n",
    "output_data = [np.empty(shapeOut, dtype=np.float32, order=\"C\")]\n",
    "\n",
    "# create an empty array for input data with the correct shape (shapeIn) and type (float32)\n",
    "input_data = [np.empty(shapeIn, dtype=np.float32, order=\"C\")]\n",
    "\n",
    "# create a variable to store the first element of the input_data\n",
    "image = input_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca17e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will also define a few functions to calculate softmax. \n",
    "# Softmax is an activation function that predicts a multinomial probability distribution. \n",
    "# So you can see the probabilities or how likely each output was. \n",
    "def calculate_softmax(data):\n",
    "    result = np.exp(data)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88945c94",
   "metadata": {},
   "source": [
    "### Step 6: Run DPU to make predictions ### \n",
    "We can now classify a couple of digit pictures. For each picture, \n",
    "the classification result (shown as 'Prediction') is displayed on top of \n",
    "the picture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try changing the number of pictures to 2! \n",
    "# how about 5? 13? \n",
    "# make sure to rerun the cell when you change code!\n",
    "num_pics  = 10\n",
    "\n",
    "# format the pictures using matplotlib\n",
    "fix, ax = plt.subplots(1, num_pics, figsize=(12,12))\n",
    "plt.tight_layout()\n",
    "\n",
    "# iterate through num_pics amount of images in the database \n",
    "for i in range(num_pics):\n",
    "    image[0,...] = test_data[i]\n",
    "    \n",
    "    # this is where the model is making its predictions\n",
    "    job_id = dpu.execute_async(input_data, output_data)\n",
    "    dpu.wait(job_id)\n",
    "    \n",
    "    # reshape the data in the output\n",
    "    temp = [j.reshape(1, outputSize) for j in output_data]\n",
    "    \n",
    "    # use the softmax function we defined above to calculate the probabilities of each possible output\n",
    "    softmax = calculate_softmax(temp[0][0])\n",
    "    prediction = softmax.argmax()\n",
    "\n",
    "    # display the image and its associated prediction\n",
    "    ax[i].set_title('Prediction: {}'.format(prediction))\n",
    "    ax[i].axis('off')\n",
    "    ax[i].imshow(test_data[i,:,:,0], 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4106229f",
   "metadata": {},
   "source": [
    "We can also evaluate on the entire test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7f3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define how many images there are in the database\n",
    "total = test_data.shape[0]\n",
    "\n",
    "# create an empty array with the same shape and type as the test_label array\n",
    "predictions = np.empty_like(test_label)\n",
    "print(\"Classifying {} digit pictures ...\".format(total))\n",
    "\n",
    "# this line will be so we can time how long our predictions take\n",
    "start = time()\n",
    "\n",
    "# iterate through all the images in the database \n",
    "for i in range(total):\n",
    "    image[0,...] = test_data[i]\n",
    "    \n",
    "    # model is making its predictions\n",
    "    job_id = dpu.execute_async(input_data, output_data)\n",
    "    dpu.wait(job_id)\n",
    "    \n",
    "    # reshape the data in the output\n",
    "    temp = [j.reshape(1, outputSize) for j in output_data]\n",
    "    \n",
    "    # use the softmax function we defined above to calculate the probabilities of each possible output\n",
    "    softmax = calculate_softmax(temp[0][0])\n",
    "    predictions[i] = softmax.argmax()\n",
    "\n",
    "# keep track of end time\n",
    "stop = time()\n",
    "\n",
    "# sum up how often the model is correct to calculate accuracy later \n",
    "correct = np.sum(predictions==test_label)\n",
    "\n",
    "# calculate the execution time by taking the latest time subtracted by earlier time\n",
    "execution_time = stop-start\n",
    "\n",
    "# print results!\n",
    "print(\"Overall accuracy: {}\".format(correct/total))\n",
    "print(\"  Execution time: {:.4f}s\".format(execution_time))\n",
    "print(\"      Throughput: {:.4f}FPS\".format(total/execution_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a7e0f4",
   "metadata": {},
   "source": [
    "#### ü§©WHOA! This output means that your model was able to classify almost 1 or 100% of the handwritten images correctly in a few seconds!ü§© #### \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdd772c",
   "metadata": {},
   "source": [
    "## ü§î How good is your handwriting? ü§î ##\n",
    "\n",
    "### Step 7: Using the USB Camera üì∑\n",
    "Next, we will connect the USB Camera and capture a few frames of your handwritten digits to see how accurately the model can classify your numbers! \n",
    "\n",
    "But let's add a twist! When we print out the prediction, let's also display the prediction on the RGB LED Stick in red! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf298415",
   "metadata": {},
   "source": [
    "#### üåà Let's set the color of the RGB LED Stick üåà #### \n",
    "The RGB LED stick command \n",
    "\n",
    "`led_stick.set_pixel(index, rgb(red, green, blue))` \n",
    "\n",
    "has these parameters\n",
    "* parameter 1: the index of led in Grove RGB LED Stick (number);   \n",
    "* parameter 2: the color of led in Grove RGB LED Stick (RGB). \n",
    "\n",
    "The best way to represent this color is in the rgb(*red, green, blue*) format. RGB stands for <span style=\"color:red\">*red*</span>, <span style=\"color:green\">*green*</span>, and <span style=\"color:blue\">*blue*</span>. You can set the value of each color as a number from 0-255, the greater the number means the more of that color you will have in your overall color. \n",
    "\n",
    "You can use the internet to look up the rgb values of some cool colors! \n",
    "Some cool colors to remember are:\n",
    "* <span style=\"color:red\">red (255, 0, 0)</span>\n",
    "* <span style=\"color:orange\">orange (255, 165, 0)</span>\n",
    "* <span style=\"color:yellow\">yellow (0, 255, 255)</span>\n",
    "* <span style=\"color:green\">green (0, 255, 0)</span>\n",
    "* <span style=\"color:blue\">blue (0, 0, 255)</span>\n",
    "* <span style=\"color:purple\">purple (255, 0, 255)</span>\n",
    "* <span style=\"color:pink\">pink (my favorite!) (255, 192, 203)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7998e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes your rgb values and converts it into one number\n",
    "# to pass into the set_pixel function\n",
    "def rgb(r, g, b):\n",
    "    return int('0x{:02x}{:02x}{:02x}'.format(r, g, b), 16)\n",
    "\n",
    "# try changing the rgb values to make some cool colors! \n",
    "led_stick.set_pixel(0, rgb(255, 0, 0))\n",
    "led_stick.set_pixel(1, rgb(255, 35, 0))\n",
    "led_stick.set_pixel(2, rgb(255, 87, 0))\n",
    "led_stick.set_pixel(3, rgb(255, 140, 0))\n",
    "led_stick.set_pixel(4, rgb(255, 193, 0))\n",
    "led_stick.set_pixel(5, rgb(255, 246, 0))\n",
    "led_stick.set_pixel(6, rgb(212, 255, 0))\n",
    "led_stick.set_pixel(7, rgb(159, 255, 0))\n",
    "led_stick.set_pixel(8, rgb(106, 255, 0))\n",
    "led_stick.set_pixel(9, rgb(0, 255, 0))\n",
    "\n",
    "# finally use the line below to actually display the colors\n",
    "led_stick.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is the expected output of the led stick.\n",
    "<img align =\"center\" src=\"img\\rainbowled.jpg\"  width=\"550\" height=\"400\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae774d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make this a function that we can call \n",
    "# to make it easier to set the colors\n",
    "def setRGBLedStick(numOfLeds, color):\n",
    "    led_stick.clear()\n",
    "    for led in range(numOfLeds):\n",
    "        led_stick.set_pixel(led, color)\n",
    "    led_stick.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e734b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the function, here we are having all 10 leds light up\n",
    "setRGBLedStick(10, rgb(150,0,150))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is the expected output of the led stick.\n",
    "<img align =\"center\" src=\"img\\pinkled.jpg\"  width=\"550\" height=\"400\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1e4e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are 0 leds lit up\n",
    "setRGBLedStick(0, rgb(150,0,150))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is the expected output of the led stick.\n",
    "<img align =\"center\" src=\"img\\offled.jpg\"  width=\"550\" height=\"400\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "7e90a7e6",
   "metadata": {},
   "source": [
    "#### üì∏Taking a pictureüì∏ #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee64fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the camera\n",
    "camera = cv2.VideoCapture(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b2a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab a single frame of video\n",
    "ret, frame = camera.read()\n",
    "# show camera frame\n",
    "plt.imshow(frame)\n",
    "# try changing the title to your name!\n",
    "plt.title('Hello!')\n",
    "# display the frame to the notebook\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3606e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close camera\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639fa79c",
   "metadata": {},
   "source": [
    "Let's do some pre-processing to make your image a 28x28 pixel handwritten image to be fed into the model! Also, let's stick this in a preprocessing function for later use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818aff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(frame):\n",
    "    # resizes the image into a 28x28 pixel array\n",
    "    img_resized = cv2.resize(frame, (28,28), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # use the cvtColor() function from the cv2 library to convert the frame to a grayscale image\n",
    "    img_gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # let's help the model by doing some image thresholding\n",
    "    # if the pixels in the image are above a certain threshold, then they will just become white\n",
    "    # otherwise, the pixel will just be black, this will enable us to send only \n",
    "    # black and white images into the model\n",
    "    ret,img_thresh = cv2.threshold(img_gray,120,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # preview resized and colored image\n",
    "    plt.imshow(img_thresh, 'gray')\n",
    "    \n",
    "    # pre-process it with the two steps mentioned in step 4\n",
    "    img_thresh = img_thresh[np.newaxis, :, :]\n",
    "\n",
    "    normalized_data = np.asarray(img_thresh/255, dtype=np.float32)\n",
    "    test_data = np.expand_dims(normalized_data, axis=3)\n",
    "    \n",
    "    return (test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b7493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_img = preprocess_img(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb27206",
   "metadata": {},
   "source": [
    "Let's run our image through the model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8a1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "image[0,...] = preprocessed_img\n",
    "job_id = dpu.execute_async(input_data, output_data)\n",
    "dpu.wait(job_id)\n",
    "temp = [j.reshape(1, outputSize) for j in output_data]\n",
    "softmax = calculate_softmax(temp[0][0])\n",
    "prediction = softmax.argmax()\n",
    "\n",
    "# this prints out what the model thinks is the correct digit\n",
    "print (\"Prediction: \" + str(prediction))\n",
    "setRGBLedStick(prediction, rgb(150,0,150))\n",
    "\n",
    "# this prints the probabilities that the model attributes to each digit!\n",
    "# each value represents the digits 0-9, the greatest value is the digit the\n",
    "# model is the most confident in\n",
    "print (softmax)\n",
    "plt.imshow(preprocessed_img[0,:,:,0], 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aba650",
   "metadata": {},
   "source": [
    "#### üé• Taking a video üé• #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0502c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a running webcam video, let's import these libraries\n",
    "from IPython.display import display, Image\n",
    "import ipywidgets as widgets\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d586691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code below will set up a stop button that we can click to stop the camera feed\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Description',                         \n",
    "    icon='square' # (FontAwesome names without the `fa-` prefix)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6079b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can create this function to capture the webcam video,\n",
    "# preprocess each frame, and set each frame through the model\n",
    "def view(button):\n",
    "    # let's initialize the camera\n",
    "    cap = cv2.VideoCapture(-1)\n",
    "    display_handle=display(None, display_id=True)\n",
    "    \n",
    "    # this loop will run until you press the red stop button\n",
    "    while True:\n",
    "        # read in a frame from the camera \n",
    "        _, frame = cap.read()\n",
    "        _, framee = cv2.imencode('.jpeg', frame)\n",
    "        # update the frame to your display on the notebook\n",
    "        display_handle.update(Image(data=framee.tobytes()))\n",
    "        \n",
    "        # preprocess and send the frame through the model\n",
    "        image[0,...] = preprocess_img(frame)\n",
    "        job_id = dpu.execute_async(input_data, output_data)\n",
    "        dpu.wait(job_id)\n",
    "        temp = [j.reshape(1, outputSize) for j in output_data]\n",
    "        softmax = calculate_softmax(temp[0][0])\n",
    "        prediction = softmax.argmax()\n",
    "        \n",
    "        # print the prediction\n",
    "        print (\"Prediction: \" + str(prediction), end=\"\\r\")\n",
    "        # light up the led stick according to the prediction\n",
    "        setRGBLedStick(prediction, rgb(150,0,150))\n",
    "        \n",
    "        # this if-statement stops the loop when a stop-button is pressed\n",
    "        if stopButton.value==True:\n",
    "            cap.release()\n",
    "            display_handle.update(None)\n",
    "            setRGBLedStick(0, rgb(150,0,150))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f88e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a display that will run until the stop button is pressed\n",
    "display(stopButton)\n",
    "thread = threading.Thread(target=view, args=(stopButton,))\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe04d865",
   "metadata": {},
   "source": [
    "### üßº Step 7: Clean up üßº ### \n",
    "We can let Python garbage-collect the unused objects and stuff from all this code we just ran. This will make sure we can run other notebooks without any issues! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363482d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del overlay\n",
    "del dpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452b1170",
   "metadata": {},
   "source": [
    "## Summary ##\n",
    "Let's summarize, in this notebook we\n",
    "* understood what the MNIST database is,\n",
    "* learned how to use the MNIST Classifier Model, \n",
    "* programmed the grove <span style=\"color:red\">R</span><span style=\"color:green\">G</span><span style=\"color:blue\">B</span> LED stick, and\n",
    "* explored how we can use the MNIST database and model in different ways! \n",
    "\n",
    "### ‚ú® Bonus Challenges! ‚ú® ###\n",
    "Here are some optional challenges for you to work through! \n",
    "* Display the prediction of the model in different colors on the RGB LED stick so it is not all one color\n",
    "    * hint: you may have to change the `setRGBLedStick()` function above \n",
    "    \n",
    "    \n",
    "* Take a look at the softmax function, what does it do? If you are not quite sure, ask one of us! \n",
    "    * Is there a way to differentiate how confident the model is in its predictions using this function?\n",
    "    * Try changing the color of the RGB LED bar to correspond to how confident the model is in its prediction. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
